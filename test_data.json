{
  "cached_articles": [
    {
      "source": "arXiv • Alzayer et al.",
      "title": "Coupled Diffusion Sampling for Training-Free Multi-View Image Editing",
      "link": "http://arxiv.org/abs/2510.14981v1",
      "summary": "Researchers developed an inference-time diffusion sampling method that enables multi-view consistent image editing using pre-trained 2D models. This approach leverages implicit 3D regularization by constraining 2D edits to follow a multi-view image distribution, which enhances consistency without the lengthy optimization typical of previous methods. The technique employs coupled diffusion sampling to generate synchronized image sequences, maintaining coherence across views. Validation across three different editing tasks showcases its versatility and potential as a universal solution for multi-view editing challenges.",
      "published": "2025-10-16T17:59:59+00:00"
    },
    {
      "source": "arXiv • Diao et al.",
      "title": "From Pixels to Words -- Towards Native Vision-Language Primitives at Scale",
      "link": "http://arxiv.org/abs/2510.14979v1",
      "summary": "NEO, a new family of native Vision-Language Models (VLMs), addresses key challenges in aligning vision and language by integrating pixel and word representations into a unified semantic space. It leverages only 390M image-text examples to develop visual perception from scratch, mitigating conflicts inherent in traditional modular models. NEO's architecture embodies various cross-modal properties, making it scalable and powerful for real-world applications. The project promotes accessibility in native VLM research, providing a robust ecosystem of reusable components. Find the code and models at: https://github.com/EvolvingLMMs-Lab/NEO.",
      "published": "2025-10-16T17:59:58+00:00"
    },
    {
      "source": "arXiv • Zhang et al.",
      "title": "Agentic Design of Compositional Machines",
      "link": "http://arxiv.org/abs/2510.14978v1",
      "summary": "Researchers have developed BesiegeField, a testbed for evaluating large language models (LLMs) in compositional machine design, allowing for part-based construction and physical simulation. This environment benchmarks LLMs on their ability to perform spatial reasoning, strategic assembly, and instruction-following. Current open-source models struggle with these tasks, prompting exploration of reinforcement learning (RL) for enhancements. The study also includes a curated cold-start dataset and outlines challenges in merging language processing with machine design and physical reasoning.",
      "published": "2025-10-16T17:59:58+00:00"
    },
    {
      "source": "arXiv • Kumari et al.",
      "title": "Learning an Image Editing Model without Image Editing Pairs",
      "link": "http://arxiv.org/abs/2510.14977v1",
      "summary": "A novel training paradigm for image editing models eliminates the need for paired data, addressing a major bottleneck in current methodologies. This approach directly optimizes a few-step diffusion model using feedback from vision-language models (VLMs), which assess the accuracy of edits against given instructions. Incorporating distribution matching loss ensures visual fidelity by constraining generated images to a learned image manifold. Evaluations show this method matches or exceeds the performance of traditional models trained on extensive supervised data, outpacing reinforcement learning techniques like Flow-GRPO.",
      "published": "2025-10-16T17:59:57+00:00"
    },
    {
      "source": "arXiv • Huang et al.",
      "title": "Terra: Explorable Native 3D World Model with Point Latents",
      "link": "http://arxiv.org/abs/2510.14976v1",
      "summary": "Terra introduces a groundbreaking 3D world model that leverages an intrinsic 3D latent space for environment representation and generation. It employs a point-to-Gaussian variational autoencoder (P2G-VAE) to encode 3D inputs into a latent point representation, which decodes into 3D Gaussian primitives, ensuring accurate modeling of both geometry and appearance. A sparse point flow matching network (SPFlow) enhances this process by denoising point latents, supporting exact multi-view consistency and flexible rendering from any perspective. Extensive tests on ScanNet v2 demonstrate Terra's state-of-the-art capabilities in reconstruction and generation while maintaining high 3D consistency, marking a significant advancement in world modeling efficiency.",
      "published": "2025-10-16T17:59:56+00:00"
    }
  ],
  "cached_joke": "Why did Terra break up with its last model? It just couldn't handle the emotional depth of their 3D relationship!",
  "cached_joke_article": {
    "title": "Terra: Explorable Native 3D World Model with Point Latents",
    "link": "http://arxiv.org/abs/2510.14976v1"
  }
}
