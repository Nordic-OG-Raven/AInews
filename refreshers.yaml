---
ml_research:
  - name: "Gradient Descent"
    why: "Core algorithm for minimizing loss functions in training models."
    misconception: "People think it always finds the global minimum in non-convex problems."
    explanation_prompt: "Explain Gradient Descent in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Gradient_descent"
  - name: "Stochastic Gradient"
    why: "Enables scalable optimization using mini-batches for noisy but faster updates."
    misconception: "Assumed equivalent in convergence behavior to full-batch gradient descent."
    explanation_prompt: "Explain Stochastic Gradient in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Stochastic_gradient_descent"
  - name: "Backpropagation"
    why: "Computes gradients efficiently through layered networks using the chain rule."
    misconception: "Confused as a separate optimizer rather than a gradient calculation method."
    explanation_prompt: "Explain Backpropagation in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Backpropagation"
  - name: "Activation Functions"
    why: "Introduce nonlinearity, enabling networks to approximate complex functions."
    misconception: "Assuming ReLU always outperforms sigmoid or tanh in every setting."
    explanation_prompt: "Explain Activation Functions in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Activation_function"
  - name: "Loss Functions"
    why: "Define what the model optimizes and encode task-specific goals."
    misconception: "Believing cross-entropy and MSE are interchangeable across tasks."
    explanation_prompt: "Explain Loss Functions in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Loss_function"
  - name: "Overfitting Control"
    why: "Prevents memorization, improving generalization to unseen data."
    misconception: "Thinking more data always fixes overfitting without regularization."
    explanation_prompt: "Explain Overfitting Control in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Overfitting"
  - name: "Bias–Variance Tradeoff"
    why: "Explains errors from model simplicity vs. complexity and guides tuning."
    misconception: "Assuming reducing bias never increases variance."
    explanation_prompt: "Explain Bias–Variance Tradeoff in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff"
  - name: "Regularization (L2)"
    why: "Penalizes large weights to reduce variance and improve generalization."
    misconception: "Confusing L2 with early stopping or dropout effects."
    explanation_prompt: "Explain Regularization (L2) in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Tikhonov_regularization"
  - name: "Dropout Regularization"
    why: "Randomly disables units to prevent co-adaptation and overfitting."
    misconception: "Believing dropout should be used during inference."
    explanation_prompt: "Explain Dropout Regularization in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Dropout_(neural_networks)"
  - name: "Batch Normalization"
    why: "Stabilizes and accelerates training by normalizing activations."
    misconception: "Assuming it always allows much higher learning rates safely."
    explanation_prompt: "Explain Batch Normalization in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Batch_normalization"
  - name: "Learning Rate"
    why: "Controls step size in optimization and affects convergence stability."
    misconception: "Using a single constant value is optimal for all training phases."
    explanation_prompt: "Explain Learning Rate in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Learning_rate"
  - name: "Early Stopping"
    why: "Halts training before overfitting by monitoring validation performance."
    misconception: "Treating it as a substitute for explicit regularization."
    explanation_prompt: "Explain Early Stopping in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Early_stopping"
  - name: "Vanishing Gradients"
    why: "Diagnosis for unstable training in deep or recurrent networks."
    misconception: "Assuming it occurs only with sigmoid activations."
    explanation_prompt: "Explain Vanishing Gradients in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Vanishing_gradient_problem"
  - name: "Convolutional Networks"
    why: "Exploit spatial locality for images and signals via shared kernels."
    misconception: "Believing CNNs cannot process sequences or 1D signals."
    explanation_prompt: "Explain Convolutional Networks in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Convolutional_neural_network"
  - name: "Recurrent Networks"
    why: "Model temporal dependencies by maintaining hidden state over time."
    misconception: "Equating all RNNs with LSTMs in behavior and capability."
    explanation_prompt: "Explain Recurrent Networks in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Recurrent_neural_network"
  - name: "LSTM/GRU Units"
    why: "Use gating to mitigate vanishing gradients in sequence tasks."
    misconception: "Assuming LSTMs always outperform simpler RNNs regardless of data."
    explanation_prompt: "Explain LSTM/GRU Units in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Long_short-term_memory"
  - name: "Attention Mechanism"
    why: "Lets models focus on relevant parts of input when making predictions."
    misconception: "Thinking attention and interpretability are the same thing."
    explanation_prompt: "Explain Attention Mechanism in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Attention_(machine_learning)"
  - name: "Transformer Models"
    why: "State-of-the-art architecture for sequence modeling without recurrence."
    misconception: "Assuming transformers inherently require infinite data to train."
    explanation_prompt: "Explain Transformer Models in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)"
  - name: "Seq2Seq Models"
    why: "Map input sequences to output sequences across tasks like translation."
    misconception: "Confusing encoder–decoder with attention as mandatory."
    explanation_prompt: "Explain Seq2Seq Models in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Sequence-to-sequence"
  - name: "Word Embeddings"
    why: "Represent tokens in dense vectors capturing semantic relationships."
    misconception: "Believing embeddings are unique and directly interpretable dimensions."
    explanation_prompt: "Explain Word Embeddings in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Word_embedding"
  - name: "Transfer Learning"
    why: "Reuses knowledge from a source task to improve a target task."
    misconception: "Assuming naive fine-tuning never causes catastrophic forgetting."
    explanation_prompt: "Explain Transfer Learning in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Transfer_learning"
  - name: "Data Augmentation"
    why: "Expands training data variability to improve robustness."
    misconception: "Thinking augmentation can replace real data collection entirely."
    explanation_prompt: "Explain Data Augmentation in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Data_augmentation"
  - name: "Hyperparameter Tuning"
    why: "Systematically searches settings that optimize model performance."
    misconception: "Confusing hyperparameters with learned model parameters."
    explanation_prompt: "Explain Hyperparameter Tuning in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Hyperparameter_optimization"
  - name: "Cross-Validation"
    why: "Estimates generalization error using resampling schemes."
    misconception: "Treating test and validation folds as interchangeable."
    explanation_prompt: "Explain Cross-Validation in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
  - name: "Universal Approximation"
    why: "Shows neural nets can approximate continuous functions under conditions."
    misconception: "Misread as guaranteeing easy training or good generalization."
    explanation_prompt: "Explain Universal Approximation in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Universal_approximation_theorem"
ai_business:
  - name: "Nonconvex Optimization"
    why: "Describes realistic loss landscapes encountered in deep learning."
    misconception: "Assuming local minima are always poor solutions."
    explanation_prompt: "Explain Nonconvex Optimization in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Nonconvex_optimization"
  - name: "MLOps Lifecycle"
    why: "Coordinates development, deployment, and maintenance of ML systems."
    misconception: "Equated with simple CI/CD without data and monitoring concerns."
    explanation_prompt: "Explain MLOps Lifecycle in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/MLOps"
  - name: "Batch vs Stream"
    why: "Determines architecture and latency for data processing and inference."
    misconception: "Assuming streaming always beats batch for freshness and cost."
    explanation_prompt: "Explain Batch vs Stream in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Batch_processing"
  - name: "Real-Time Serving"
    why: "Supports low-latency predictions for interactive products."
    misconception: "Believing throughput and latency can be maximized simultaneously."
    explanation_prompt: "Explain Real-Time Serving in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Latency_(engineering)"
  - name: "A/B Testing"
    why: "Evaluates product impact causally by randomized experiments."
    misconception: "Stopping early when results look good without power checks."
    explanation_prompt: "Explain A/B Testing in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/A/B_testing"
  - name: "Canary Releases"
    why: "Limits blast radius by rolling out models to small segments first."
    misconception: "Confusing canaries with dark launches or shadow tests."
    explanation_prompt: "Explain Canary Releases in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Canary_release"
  - name: "Blue–Green Deploys"
    why: "Enables zero-downtime switches between model versions."
    misconception: "Assuming it removes the need for rollback planning."
    explanation_prompt: "Explain Blue–Green Deploys in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Blue%E2%80%93green_deployment"
  - name: "Shadow Testing"
    why: "Runs new models behind the scenes to validate behavior safely."
    misconception: "Mistaken as releasing features to users without control."
    explanation_prompt: "Explain Shadow Testing in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Dark_launch"
  - name: "Model Monitoring"
    why: "Detects data and concept drift to prevent silent performance drops."
    misconception: "Thinking accuracy alone suffices for production health."
    explanation_prompt: "Explain Model Monitoring in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Concept_drift"
  - name: "Feature Engineering"
    why: "Transforms raw data into informative inputs improving model value."
    misconception: "Assuming end-to-end models remove need for features."
    explanation_prompt: "Explain Feature Engineering in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Feature_engineering"
  - name: "Data Versioning"
    why: "Tracks datasets to reproduce experiments and deployments."
    misconception: "Believing code versioning alone ensures reproducibility."
    explanation_prompt: "Explain Data Versioning in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Version_control"
  - name: "Reproducible Pipelines"
    why: "Guarantee consistent results across environments and times."
    misconception: "Confusing determinism with reproducibility under data change."
    explanation_prompt: "Explain Reproducible Pipelines in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Reproducibility"
  - name: "SLA and SLOs"
    why: "Set reliability targets for prediction services and teams."
    misconception: "Treating SLAs as internal metrics rather than external contracts."
    explanation_prompt: "Explain SLA and SLOs in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Service-level_agreement"
  - name: "Capacity Planning"
    why: "Ensures sufficient resources for peak loads and growth."
    misconception: "Overfitting infra to past averages instead of percentiles."
    explanation_prompt: "Explain Capacity Planning in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Capacity_planning"
  - name: "Cost Management"
    why: "Controls compute, storage, and egress expenses for ML services."
    misconception: "Ignoring total cost of ownership beyond cloud bills."
    explanation_prompt: "Explain Cost Management in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Total_cost_of_ownership"
  - name: "Feedback Loops"
    why: "Model outputs influence future data and user behavior."
    misconception: "Assuming offline metrics equal long-term business impact."
    explanation_prompt: "Explain Feedback Loops in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Feedback"
  - name: "Human-in-the-Loop"
    why: "Combines human judgment with automation for quality and safety."
    misconception: "Treating humans only as labelers rather than decision partners."
    explanation_prompt: "Explain Human-in-the-Loop in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Human-in-the-loop"
  - name: "Design of Experiments"
    why: "Structures tests to isolate causal effects efficiently."
    misconception: "Changing multiple factors without randomization or controls."
    explanation_prompt: "Explain Design of Experiments in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Design_of_experiments"
  - name: "Observability"
    why: "Enables inference from outputs to internal states for debugging."
    misconception: "Equating logs alone with complete observability."
    explanation_prompt: "Explain Observability in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Observability"
  - name: "Caching Strategies"
    why: "Reduce latency and cost by reusing frequent results."
    misconception: "Assuming caches are always consistent and risk-free."
    explanation_prompt: "Explain Caching Strategies in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Cache_(computing)"
  - name: "Message Queues"
    why: "Decouple services and smooth load for robust inference pipelines."
    misconception: "Using queues as a substitute for proper backpressure."
    explanation_prompt: "Explain Message Queues in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Message_queue"
  - name: "Idempotent APIs"
    why: "Ensures safe retries without duplicate side effects in inference flows."
    misconception: "Thinking idempotence means operations are read-only."
    explanation_prompt: "Explain Idempotent APIs in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Idempotence"
  - name: "Rollback Planning"
    why: "Restores prior versions when degradations are detected post-release."
    misconception: "Relying on hotfixes instead of versioned rollbacks."
    explanation_prompt: "Explain Rollback Planning in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Version_control"
  - name: "Regulatory Compliance"
    why: "Aligns ML products with laws to avoid sanctions and reputational harm."
    misconception: "Treating compliance as a one-time launch checklist."
    explanation_prompt: "Explain Regulatory Compliance in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Regulatory_compliance"
  - name: "Privacy by Design"
    why: "Builds privacy safeguards into systems from the outset."
    misconception: "Believing anonymization alone fulfills privacy obligations."
    explanation_prompt: "Explain Privacy by Design in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Privacy_by_design"
ai_ethics:
  - name: "Incident Response"
    why: "Coordinates rapid mitigation of outages or harmful model behavior."
    misconception: "Confusing postmortems with blame assignments."
    explanation_prompt: "Explain Incident Response in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Incident_response"
  - name: "Algorithmic Bias"
    why: "Systematic errors can disadvantage groups in model outcomes."
    misconception: "Assuming balanced datasets automatically remove bias."
    explanation_prompt: "Explain Algorithmic Bias in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Algorithmic_bias"
  - name: "Fairness Metrics"
    why: "Provide formal criteria to assess equitable model performance."
    misconception: "Thinking all fairness metrics can be satisfied simultaneously."
    explanation_prompt: "Explain Fairness Metrics in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Fairness_(machine_learning)"
  - name: "Equalized Odds"
    why: "Requires equal error rates across protected groups."
    misconception: "Confusing it with demographic parity on outcomes."
    explanation_prompt: "Explain Equalized Odds in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Equalized_odds"
  - name: "Demographic Parity"
    why: "Demands equal positive rates regardless of group membership."
    misconception: "Mistaking it for equal accuracy across groups."
    explanation_prompt: "Explain Demographic Parity in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Demographic_parity"
  - name: "Disparate Impact"
    why: "Flags policies with adverse effects despite neutral intent."
    misconception: "Believing intent determines discrimination legality."
    explanation_prompt: "Explain Disparate Impact in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Disparate_impact"
  - name: "Informed Consent"
    why: "Ensures individuals understand and agree to data use."
    misconception: "Treating vague opt-ins as fully informed consent."
    explanation_prompt: "Explain Informed Consent in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Informed_consent"
  - name: "Data Minimization"
    why: "Limits collection to necessary data, reducing risk exposure."
    misconception: "Assuming minimization conflicts with performance by default."
    explanation_prompt: "Explain Data Minimization in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Data_minimization"
  - name: "Differential Privacy"
    why: "Protects individual contributions with formal privacy guarantees."
    misconception: "Believing epsilon has an absolute universal 'safe' value."
    explanation_prompt: "Explain Differential Privacy in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Differential_privacy"
  - name: "K-Anonymity"
    why: "Prevents re-identification by ensuring records are indistinguishable."
    misconception: "Thinking k-anonymity alone prevents all linkage attacks."
    explanation_prompt: "Explain K-Anonymity in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/K-anonymity"
  - name: "Federated Learning"
    why: "Trains models across devices without centralizing raw data."
    misconception: "Assuming it inherently guarantees privacy without noise."
    explanation_prompt: "Explain Federated Learning in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Federated_learning"
  - name: "Explainable AI"
    why: "Provides human-understandable reasons for model behavior."
    misconception: "Equating post-hoc explanations with ground truth causality."
    explanation_prompt: "Explain Explainable AI in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Explainable_artificial_intelligence"
  - name: "Interpretability"
    why: "Assesses how well humans can comprehend model mechanisms."
    misconception: "Assuming interpretability and accuracy are mutually exclusive."
    explanation_prompt: "Explain Interpretability in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Interpretability"
  - name: "Transparency"
    why: "Discloses information about data, models, and processes."
    misconception: "Thinking transparency alone ensures fairness or safety."
    explanation_prompt: "Explain Transparency in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Transparency_(behavior)"
  - name: "Accountability"
    why: "Assigns responsibility for model decisions and outcomes."
    misconception: "Assuming accountability ends with technical teams."
    explanation_prompt: "Explain Accountability in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Accountability"
  - name: "AI Safety"
    why: "Studies preventing unintended harmful behavior in AI systems."
    misconception: "Equating safety solely with adversarial robustness."
    explanation_prompt: "Explain AI Safety in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/AI_safety"
  - name: "Adversarial ML"
    why: "Examines vulnerabilities from crafted inputs that fool models."
    misconception: "Assuming training accuracy implies adversarial robustness."
    explanation_prompt: "Explain Adversarial ML in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Adversarial_machine_learning"
  - name: "Robustness"
    why: "Measures performance stability under distributional shifts or noise."
    misconception: "Confusing robustness with simple regularization strength."
    explanation_prompt: "Explain Robustness in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Robustness_(computer_science)"
  - name: "Surveillance Risks"
    why: "Relates to mass data collection and potential rights violations."
    misconception: "Assuming public data use is always ethically permissible."
    explanation_prompt: "Explain Surveillance Risks in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Surveillance"
  - name: "Facial Recognition"
    why: "Raises issues of accuracy disparities and pervasive tracking."
    misconception: "Believing accuracy on one dataset generalizes to all groups."
    explanation_prompt: "Explain Facial Recognition in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Facial_recognition_system"
  - name: "Data Governance"
    why: "Sets policies and processes for responsible data lifecycle management."
    misconception: "Equating governance with access denial rather than stewardship."
    explanation_prompt: "Explain Data Governance in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Data_governance"
  - name: "GDPR Basics"
    why: "Core EU privacy law shaping consent, rights, and processing."
    misconception: "Assuming GDPR applies only to EU-based companies."
    explanation_prompt: "Explain GDPR Basics in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/General_Data_Protection_Regulation"
  - name: "CCPA Overview"
    why: "California law granting consumer data rights impacting products."
    misconception: "Confusing CCPA with GDPR scope and definitions."
    explanation_prompt: "Explain CCPA Overview in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/California_Consumer_Privacy_Act"
  - name: "Value Sensitive Design"
    why: "Integrates human values into system design systematically."
    misconception: "Assuming values can be added post-deployment easily."
    explanation_prompt: "Explain Value Sensitive Design in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Value_sensitive_design"
  - name: "Causality vs Correlation"
    why: "Prevents harmful policy decisions based on spurious links."
    misconception: "Treating correlations as causal evidence in sensitive domains."
    explanation_prompt: "Explain Causality vs Correlation in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Causality"
  - name: "Human Oversight"
    why: "Ensures meaningful review and override of automated decisions."
    misconception: "Assuming oversight is effective without feedback channels."
    explanation_prompt: "Explain Human Oversight in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Human-in-the-loop"
data_science:
  - name: "Content Moderation"
    why: "Balances safety, speech, and fairness in automated systems."
    misconception: "Believing automated moderation is fully objective."
    explanation_prompt: "Explain Content Moderation in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Content_moderation"
  - name: "Probability Basics"
    why: "Foundation for modeling uncertainty and making predictions."
    misconception: "Confusing odds with probabilities and frequencies."
    explanation_prompt: "Explain Probability Basics in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Probability"
  - name: "Bayes Theorem"
    why: "Updates beliefs with evidence, central to probabilistic inference."
    misconception: "Treating priors as arbitrary and inconsequential."
    explanation_prompt: "Explain Bayes Theorem in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Bayes%27_theorem"
  - name: "Sampling Methods"
    why: "Determine representativeness and variance of estimates."
    misconception: "Assuming larger samples always fix sampling bias."
    explanation_prompt: "Explain Sampling Methods in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Sampling_(statistics)"
  - name: "Central Limit Theorem"
    why: "Justifies normal approximations for sums and means."
    misconception: "Believing it applies regardless of sample size or dependence."
    explanation_prompt: "Explain Central Limit Theorem in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Central_limit_theorem"
  - name: "Hypothesis Testing"
    why: "Framework for deciding significance of observed effects."
    misconception: "Interpreting p-values as the probability the null is true."
    explanation_prompt: "Explain Hypothesis Testing in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Statistical_hypothesis_testing"
  - name: "P-Values"
    why: "Quantify compatibility of data with a specified null model."
    misconception: "Treating 0.05 as a magic threshold for truth."
    explanation_prompt: "Explain P-Values in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/P-value"
  - name: "Confidence Intervals"
    why: "Provide ranges for parameter estimates with specified coverage."
    misconception: "Interpreting them as direct probabilities for parameters."
    explanation_prompt: "Explain Confidence Intervals in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Confidence_interval"
  - name: "Statistical Power"
    why: "Controls false negatives and sample size planning."
    misconception: "Confusing power with significance level."
    explanation_prompt: "Explain Statistical Power in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Statistical_power"
  - name: "Correlation vs Causation"
    why: "Prevents misinterpretation of associations as causal effects."
    misconception: "Assuming high correlation implies causality."
    explanation_prompt: "Explain Correlation vs Causation in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation"
  - name: "Linear Regression"
    why: "Baseline model for prediction and inference with continuous outcomes."
    misconception: "Ignoring assumptions like linearity and homoscedasticity."
    explanation_prompt: "Explain Linear Regression in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Linear_regression"
  - name: "Logistic Regression"
    why: "Standard classifier for binary outcomes with probabilistic outputs."
    misconception: "Treating predicted probabilities as calibrated by default."
    explanation_prompt: "Explain Logistic Regression in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Logistic_regression"
  - name: "Regularization L1/L2"
    why: "Controls model complexity and improves generalization."
    misconception: "Assuming penalties do not bias parameter estimates."
    explanation_prompt: "Explain Regularization L1/L2 in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Regularization_(mathematics)"
  - name: "Feature Selection"
    why: "Reduces overfitting and improves interpretability and speed."
    misconception: "Selecting features solely by univariate correlation."
    explanation_prompt: "Explain Feature Selection in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Feature_selection"
  - name: "Principal Components"
    why: "Transforms correlated features into orthogonal components."
    misconception: "Interpreting PCs as the original features with weights."
    explanation_prompt: "Explain Principal Components in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Principal_component_analysis"
  - name: "Time Series Basics"
    why: "Addresses autocorrelation, trend, and seasonality in temporal data."
    misconception: "Applying IID assumptions directly to time series."
    explanation_prompt: "Explain Time Series Basics in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Time_series"
  - name: "Stationarity Checks"
    why: "Determines valid modeling choices and differencing needs."
    misconception: "Confusing strict, weak, and trend stationarity."
    explanation_prompt: "Explain Stationarity Checks in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Stationary_process"
  - name: "ARIMA Modeling"
    why: "Classical approach for univariate time series forecasting."
    misconception: "Treating ARIMA as a black box without diagnostics."
    explanation_prompt: "Explain ARIMA Modeling in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average"
  - name: "Missing Data"
    why: "Handling mechanisms (MCAR/MAR/MNAR) affects inference validity."
    misconception: "Assuming mean imputation is harmless."
    explanation_prompt: "Explain Missing Data in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Missing_data"
  - name: "Outlier Treatment"
    why: "Prevents extreme values from distorting models and metrics."
    misconception: "Removing outliers solely by z-score without context."
    explanation_prompt: "Explain Outlier Treatment in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Outlier"
  - name: "Normalization Scaling"
    why: "Ensures features are on comparable scales for many algorithms."
    misconception: "Confusing normalization with standardization."
    explanation_prompt: "Explain Normalization Scaling in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Feature_scaling"
  - name: "EDA Principles"
    why: "Reveals structure, anomalies, and hypotheses before modeling."
    misconception: "Skipping EDA when using automated pipelines."
    explanation_prompt: "Explain EDA Principles in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Exploratory_data_analysis"
  - name: "AB Test Design"
    why: "Plans experiments with randomization, control, and power."
    misconception: "Peeking repeatedly without correction."
    explanation_prompt: "Explain AB Test Design in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Design_of_experiments"
  - name: "Cross-Validation"
    why: "Estimates model performance reliably on limited data."
    misconception: "Using test data inside cross-validation loops."
    explanation_prompt: "Explain Cross-Validation in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
  - name: "SQL Joins"
    why: "Combine tables correctly to build analysis datasets."
    misconception: "Confusing inner joins with left joins and causing row loss."
    explanation_prompt: "Explain SQL Joins in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Join_(SQL)"
  - name: "SQL Windows"
    why: "Compute analytics over partitions without collapsing rows."
    misconception: "Assuming GROUP BY and window functions are interchangeable."
    explanation_prompt: "Explain SQL Windows in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Window_function_(SQL)"
  - name: "Data Visualization"
    why: "Communicates findings clearly through appropriate encodings."
    misconception: "Using 3D or dual axes when simple charts suffice."
    explanation_prompt: "Explain Data Visualization in 2-3 sentences for ML engineers who learned it in school but forgot the details. Focus on intuition and when to use it."
    source: "https://en.wikipedia.org/wiki/Data_and_information_visualization"
